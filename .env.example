# LLM API Configuration
# Choose your primary and fallback models from: openai, claude, gemini, zhipu, qwen, deepseek

# Primary LLM Provider
PRIMARY_LLM_PROVIDER=openai
# Fallback LLM Provider (used if primary fails)
FALLBACK_LLM_PROVIDER=claude

# OpenAI Configuration
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_BASE_URL=https://api.openai.com/v1

# Anthropic Claude Configuration
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ANTHROPIC_MODEL=claude-3-5-sonnet-20241022
ANTHROPIC_BASE_URL=https://api.anthropic.com

# Google Gemini Configuration
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-1.5-pro
GEMINI_BASE_URL=https://generativelanguage.googleapis.com

# Zhipu AI Configuration (智谱清言)
ZHIPU_API_KEY=your_zhipu_api_key_here
ZHIPU_MODEL=glm-4
ZHIPU_BASE_URL=https://open.bigmodel.cn/api/paas/v4

# Alibaba Qwen Configuration (通义千问)
QWEN_API_KEY=your_qwen_api_key_here
QWEN_MODEL=qwen-turbo
QWEN_BASE_URL=https://dashscope.aliyuncs.com/api/v1

# DeepSeek Configuration
DEEPSEEK_API_KEY=your_deepseek_api_key_here
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# Rate Limiting (Vercel KV - Redis)
# Get these from your Vercel project settings -> Storage -> KV
KV_URL=your_kv_url_here
KV_REST_API_URL=your_kv_rest_api_url_here
KV_REST_API_TOKEN=your_kv_rest_api_token_here
KV_REST_API_READ_ONLY_TOKEN=your_kv_rest_api_read_only_token_here

# Rate Limit Settings
DAILY_READING_LIMIT=3
COOLDOWN_SECONDS=30

# Application Settings
NEXT_PUBLIC_APP_NAME=塔罗占卜
NEXT_PUBLIC_APP_DESCRIPTION=AI 智能塔罗占卜解读
NEXT_PUBLIC_SITE_URL=https://your-domain.com

# Development Settings
# Set to 'true' to disable rate limiting (for testing/demo)
NEXT_PUBLIC_DISABLE_RATE_LIMIT=false
